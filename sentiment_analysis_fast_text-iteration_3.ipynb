{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Topic</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr3CMgRv1N</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>obama</td>\n",
       "      <td>2002-04-02 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wc81vGp8qZ</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood, investment director business-unit...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>economy</td>\n",
       "      <td>2008-09-20 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDLink                                             Title  \\\n",
       "0  Tr3CMgRv1N  Obama Lays Wreath at Arlington National Cemetery   \n",
       "1  Wc81vGp8qZ       A Look at the Health of the Chinese Economy   \n",
       "\n",
       "                                            Headline     Source    Topic  \\\n",
       "0  Obama Lays Wreath at Arlington National Cemete...  USA TODAY    obama   \n",
       "1  Tim Haywood, investment director business-unit...  Bloomberg  economy   \n",
       "\n",
       "           PublishDate  Facebook  GooglePlus  LinkedIn  SentimentTitle  \\\n",
       "0  2002-04-02 00:00:00        -1          -1        -1        0.000000   \n",
       "1  2008-09-20 00:00:00        -1          -1        -1        0.208333   \n",
       "\n",
       "   SentimentHeadline  \n",
       "0          -0.053300  \n",
       "1          -0.156386  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4753"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Source'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['IDLink'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IDLink               55932\n",
       "Title                55932\n",
       "Headline             55932\n",
       "Source               55757\n",
       "Topic                55932\n",
       "PublishDate          55932\n",
       "Facebook             55932\n",
       "GooglePlus           55932\n",
       "LinkedIn             55932\n",
       "SentimentTitle       55932\n",
       "SentimentHeadline    55932\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "def remove_punctuation(input_str):\n",
    "    punctuation_free = \"\".join(i for i in input_str if i not in string.punctuation)\n",
    "    return punctuation_free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(input_str):\n",
    "    input_str = remove_punctuation(input_str)\n",
    "    input_str = remove_stopwords(input_str)\n",
    "    input_str = gensim.utils.simple_preprocess(input_str)\n",
    "    input_str = lemmatizer(input_str)\n",
    "    return input_str\n",
    "\n",
    "def feature_importance(df,model):\n",
    "    columns = df.columns\n",
    "\n",
    "    model.feature_importances_\n",
    "\n",
    "    return dict(zip(columns,model.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['all_text'] = df1['Title']+df1['Headline']\n",
    "\n",
    "# df1['all_text_processed'] = df1['all_text'].apply(lambda x: pre_process_data(x))\n",
    "\n",
    "# df1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['title_text'] = df1['Title'].apply(lambda x: pre_process_data(x))\n",
    "df1['headline_text'] = df1['Headline'].apply(lambda x: pre_process_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_text1 = df1.title_text\n",
    "template_text2 = df1.headline_text\n",
    "\n",
    "template_text = template_text1.append(template_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111864"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(template_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [obama, lay, wreath, arlington, national, ceme...\n",
       "1                         [look, health, chinese, economy]\n",
       "2           [nouriel, roubini, global, economy, not, back]\n",
       "3                              [finland, gdp, expands, in]\n",
       "4        [tourism, govt, spending, buoy, thai, economy,...\n",
       "                               ...                        \n",
       "55927    [retired, cuban, leader, fidel, castro, slamme...\n",
       "55928    [president, obama, caught, predictable, flak, ...\n",
       "55929    [while, trump, want, large, tariff, import, ma...\n",
       "55930    [microsoft, business, customer, finally, begin...\n",
       "55931    [a, we, know, listening, campaign, rhetoric, c...\n",
       "Length: 111864, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55932, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(window=5, \n",
    "                min_count=5,\n",
    "                workers=4,\n",
    "                )\n",
    "\n",
    "# build vocab first\n",
    "model.build_vocab(template_text, progress_per=100)\n",
    "\n",
    "model.epochs\n",
    "\n",
    "model.train(template_text,total_examples=model.corpus_count,epochs=model.epochs)\n",
    "\n",
    "model.save(\"word2_vec_fast_text.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exobama', 0.9890816807746887),\n",
       " ('obamaera', 0.977846622467041),\n",
       " ('boehnerobama', 0.9734190106391907),\n",
       " ('obr', 0.9707019925117493),\n",
       " ('postobama', 0.9538817405700684),\n",
       " ('antiobama', 0.9435935616493225),\n",
       " ('obamaquot', 0.9387995004653931),\n",
       " ('obamas', 0.9366296529769897),\n",
       " ('obamaseinfeld', 0.9065695405006409),\n",
       " ('obamacare', 0.8995159268379211)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('govts', 0.9193936586380005),\n",
       " ('governor', 0.8263310194015503),\n",
       " ('gov', 0.8227432370185852),\n",
       " ('vt', 0.7358570098876953),\n",
       " ('governance', 0.7076809406280518),\n",
       " ('morneau', 0.6870869398117065),\n",
       " ('government', 0.6830440163612366),\n",
       " ('fda', 0.6674199104309082),\n",
       " ('grgoiretrudeau', 0.6671798825263977),\n",
       " ('ppf', 0.6641440987586975)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('govt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3398502 , -1.0200082 , -0.17734738,  0.6572385 ,  1.7991658 ,\n",
       "        0.27955616,  0.58919024, -0.56918395,  1.2916338 , -2.346885  ,\n",
       "        0.34812832, -0.40717015, -0.39574534,  0.49153358, -0.96604234,\n",
       "       -0.36105618, -0.8926641 ,  1.0654751 ,  0.89797854,  0.24014531,\n",
       "        0.1483076 ,  2.1264896 ,  0.0611372 ,  0.13122332,  0.9164747 ,\n",
       "        0.47831082, -0.49389368,  0.25216138,  0.26483718,  0.82297087,\n",
       "       -0.27040553, -0.51653945,  0.20785622, -1.7289991 ,  1.3457798 ,\n",
       "        1.0604328 , -1.4932153 ,  0.16039884,  0.164087  ,  0.5405259 ,\n",
       "        1.2203163 , -0.02340875,  0.2579502 , -1.0355451 , -0.84879214,\n",
       "       -1.4256722 ,  1.2292757 , -0.04444612, -0.16129069, -0.36063337,\n",
       "        0.37636867, -0.37528652,  0.28977218, -0.45630655,  1.1168013 ,\n",
       "        0.7785162 , -0.9058634 ,  0.9831589 ,  0.03112453, -0.25844333,\n",
       "       -0.11396223,  0.07335816, -1.0243016 , -0.09062236, -0.10551562,\n",
       "       -0.03693302,  0.5811043 , -0.60966974,  0.3658824 , -0.77872103,\n",
       "       -0.5614746 , -0.26972625, -1.0958732 , -0.22281022,  0.6874179 ,\n",
       "        0.8391287 , -1.1494944 , -0.09036794,  0.09054997,  1.1570547 ,\n",
       "        1.2581297 ,  0.38357505,  0.67420405, -0.5086226 , -0.531978  ,\n",
       "        0.642612  , -0.47861752, -0.507278  , -0.8473856 ,  0.16125372,\n",
       "        0.17356122, -0.58393145,  1.1455642 ,  0.01424519,  0.58126014,\n",
       "        0.55200917,  0.7080878 , -0.6875787 ,  0.44395116,  0.20948626],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('member')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(\"word2_vec_fast_text.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence,model=model):\n",
    "    word_list = pre_process_data(sentence)\n",
    "    word_list = [each for each in word_list if each in model.wv.key_to_index]\n",
    "    sentence_vec = np.zeros((100,),dtype='float32')\n",
    "    sentence_len= len(word_list)\n",
    "    for each in word_list:\n",
    "        each_vector = model.wv.get_vector(each)\n",
    "        sentence_vec = np.add(sentence_vec,each_vector)\n",
    "    if sentence_len>0:\n",
    "        sentence_vec = sentence_vec/sentence_len\n",
    "    return sentence_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_similarity_score(sent1,sent2):\n",
    "    sent1_embedding = sentence_embedding(sent1)\n",
    "    sent2_embedding = sentence_embedding(sent2)\n",
    "    return 1- spatial.distance.cosine(sent1_embedding,sent2_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating text embedding for title and headline text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(data=df1,columns=['Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['title_embedding']  = df1.apply(lambda x: sentence_embedding(x['Title']),axis=1)\n",
    "\n",
    "df1['headline_embedding']  = df1.apply(lambda x: sentence_embedding(x['Headline']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_columns = ['t'+str(i) for i in range(1,101)]\n",
    "headline_columns = ['h'+str(i) for i in range(1,101)]\n",
    "\n",
    "title_dataframe = pd.DataFrame(df1['title_embedding'].to_list(), columns = title_columns)\n",
    "headline_dataframe = pd.DataFrame(df1['headline_embedding'].to_list(), columns = headline_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df1,title_dataframe,headline_dataframe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>Title</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Source</th>\n",
       "      <th>PublishDate</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "      <th>...</th>\n",
       "      <th>h91</th>\n",
       "      <th>h92</th>\n",
       "      <th>h93</th>\n",
       "      <th>h94</th>\n",
       "      <th>h95</th>\n",
       "      <th>h96</th>\n",
       "      <th>h97</th>\n",
       "      <th>h98</th>\n",
       "      <th>h99</th>\n",
       "      <th>h100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr3CMgRv1N</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemetery</td>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>2002-04-02 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543032</td>\n",
       "      <td>-0.254333</td>\n",
       "      <td>-0.232355</td>\n",
       "      <td>0.131315</td>\n",
       "      <td>-0.091420</td>\n",
       "      <td>0.867266</td>\n",
       "      <td>0.276129</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>0.251298</td>\n",
       "      <td>0.509076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wc81vGp8qZ</td>\n",
       "      <td>A Look at the Health of the Chinese Economy</td>\n",
       "      <td>Tim Haywood, investment director business-unit...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>2008-09-20 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.463229</td>\n",
       "      <td>-0.552598</td>\n",
       "      <td>-0.715039</td>\n",
       "      <td>-0.543524</td>\n",
       "      <td>-0.573413</td>\n",
       "      <td>0.441098</td>\n",
       "      <td>-0.133821</td>\n",
       "      <td>0.311327</td>\n",
       "      <td>-0.492976</td>\n",
       "      <td>0.150883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zNGH03CrZH</td>\n",
       "      <td>Nouriel Roubini: Global Economy Not Back to 2008</td>\n",
       "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.425210</td>\n",
       "      <td>0.139754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193322</td>\n",
       "      <td>-0.091477</td>\n",
       "      <td>-0.482368</td>\n",
       "      <td>-0.547905</td>\n",
       "      <td>-0.584852</td>\n",
       "      <td>0.094878</td>\n",
       "      <td>-0.203264</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>-0.710345</td>\n",
       "      <td>0.172799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3sM1H0W8ts</td>\n",
       "      <td>Finland GDP Expands In Q4</td>\n",
       "      <td>Finland's economy expanded marginally in the t...</td>\n",
       "      <td>RTT News</td>\n",
       "      <td>2015-03-01 00:06:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260081</td>\n",
       "      <td>-0.378379</td>\n",
       "      <td>0.136987</td>\n",
       "      <td>-0.115915</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.533220</td>\n",
       "      <td>-0.063789</td>\n",
       "      <td>-0.045482</td>\n",
       "      <td>-0.551651</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wUbnxgvqaZ</td>\n",
       "      <td>Tourism, govt spending buoys Thai economy in J...</td>\n",
       "      <td>Tourism and public spending continued to boost...</td>\n",
       "      <td>The Nation - Thailand&amp;#39;s English news</td>\n",
       "      <td>2015-03-01 00:11:00</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141084</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181461</td>\n",
       "      <td>-0.382395</td>\n",
       "      <td>-0.453737</td>\n",
       "      <td>-0.276794</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.278046</td>\n",
       "      <td>-0.331133</td>\n",
       "      <td>0.094336</td>\n",
       "      <td>-0.628746</td>\n",
       "      <td>0.057609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDLink                                              Title  \\\n",
       "0  Tr3CMgRv1N   Obama Lays Wreath at Arlington National Cemetery   \n",
       "1  Wc81vGp8qZ        A Look at the Health of the Chinese Economy   \n",
       "2  zNGH03CrZH   Nouriel Roubini: Global Economy Not Back to 2008   \n",
       "3  3sM1H0W8ts                          Finland GDP Expands In Q4   \n",
       "4  wUbnxgvqaZ  Tourism, govt spending buoys Thai economy in J...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Obama Lays Wreath at Arlington National Cemete...   \n",
       "1  Tim Haywood, investment director business-unit...   \n",
       "2  Nouriel Roubini, NYU professor and chairman at...   \n",
       "3  Finland's economy expanded marginally in the t...   \n",
       "4  Tourism and public spending continued to boost...   \n",
       "\n",
       "                                     Source          PublishDate  Facebook  \\\n",
       "0                                 USA TODAY  2002-04-02 00:00:00        -1   \n",
       "1                                 Bloomberg  2008-09-20 00:00:00        -1   \n",
       "2                                 Bloomberg  2012-01-28 00:00:00        -1   \n",
       "3                                  RTT News  2015-03-01 00:06:00        -1   \n",
       "4  The Nation - Thailand&#39;s English news  2015-03-01 00:11:00        -1   \n",
       "\n",
       "   GooglePlus  LinkedIn  SentimentTitle  SentimentHeadline  ...       h91  \\\n",
       "0          -1        -1        0.000000          -0.053300  ... -0.543032   \n",
       "1          -1        -1        0.208333          -0.156386  ... -0.463229   \n",
       "2          -1        -1       -0.425210           0.139754  ... -0.193322   \n",
       "3          -1        -1        0.000000           0.026064  ... -0.260081   \n",
       "4          -1        -1        0.000000           0.141084  ... -0.181461   \n",
       "\n",
       "        h92       h93       h94       h95       h96       h97       h98  \\\n",
       "0 -0.254333 -0.232355  0.131315 -0.091420  0.867266  0.276129 -0.160378   \n",
       "1 -0.552598 -0.715039 -0.543524 -0.573413  0.441098 -0.133821  0.311327   \n",
       "2 -0.091477 -0.482368 -0.547905 -0.584852  0.094878 -0.203264 -0.013735   \n",
       "3 -0.378379  0.136987 -0.115915  0.456800  0.533220 -0.063789 -0.045482   \n",
       "4 -0.382395 -0.453737 -0.276794  0.013191  0.278046 -0.331133  0.094336   \n",
       "\n",
       "        h99      h100  \n",
       "0  0.251298  0.509076  \n",
       "1 -0.492976  0.150883  \n",
       "2 -0.710345  0.172799  \n",
       "3 -0.551651  0.003335  \n",
       "4 -0.628746  0.057609  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IDLink', 'Title', 'Headline', 'Source', 'PublishDate', 'Facebook',\n",
       "       'GooglePlus', 'LinkedIn', 'SentimentTitle', 'SentimentHeadline',\n",
       "       ...\n",
       "       'h91', 'h92', 'h93', 'h94', 'h95', 'h96', 'h97', 'h98', 'h99', 'h100'],\n",
       "      dtype='object', length=216)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2[['SentimentTitle','SentimentHeadline']]\n",
    "X = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('SentimentTitle',inplace=True,axis=1)\n",
    "X.drop('SentimentHeadline',inplace=True,axis=1)\n",
    "X.drop('Title',inplace=True,axis=1)\n",
    "X.drop('Headline',inplace=True,axis=1)\n",
    "X.drop('Source',inplace=True,axis=1)\n",
    "X.drop('PublishDate',inplace=True,axis=1)\n",
    "X.drop('title_embedding',inplace=True,axis=1)\n",
    "X.drop('headline_embedding',inplace=True,axis=1)\n",
    "X.drop('IDLink',inplace=True,axis=1)\n",
    "\n",
    "try:\n",
    "    X.drop('title_text',inplace=True,axis=1)\n",
    "    X.drop('headline_text',inplace=True,axis=1)\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Topic_economy</th>\n",
       "      <th>Topic_microsoft</th>\n",
       "      <th>Topic_obama</th>\n",
       "      <th>Topic_palestine</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>...</th>\n",
       "      <th>h91</th>\n",
       "      <th>h92</th>\n",
       "      <th>h93</th>\n",
       "      <th>h94</th>\n",
       "      <th>h95</th>\n",
       "      <th>h96</th>\n",
       "      <th>h97</th>\n",
       "      <th>h98</th>\n",
       "      <th>h99</th>\n",
       "      <th>h100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.098636</td>\n",
       "      <td>0.633668</td>\n",
       "      <td>-0.693920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543032</td>\n",
       "      <td>-0.254333</td>\n",
       "      <td>-0.232355</td>\n",
       "      <td>0.131315</td>\n",
       "      <td>-0.091420</td>\n",
       "      <td>0.867266</td>\n",
       "      <td>0.276129</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>0.251298</td>\n",
       "      <td>0.509076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.218680</td>\n",
       "      <td>0.177207</td>\n",
       "      <td>0.278337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.463229</td>\n",
       "      <td>-0.552598</td>\n",
       "      <td>-0.715039</td>\n",
       "      <td>-0.543524</td>\n",
       "      <td>-0.573413</td>\n",
       "      <td>0.441098</td>\n",
       "      <td>-0.133821</td>\n",
       "      <td>0.311327</td>\n",
       "      <td>-0.492976</td>\n",
       "      <td>0.150883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187596</td>\n",
       "      <td>0.395501</td>\n",
       "      <td>-0.322583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193322</td>\n",
       "      <td>-0.091477</td>\n",
       "      <td>-0.482368</td>\n",
       "      <td>-0.547905</td>\n",
       "      <td>-0.584852</td>\n",
       "      <td>0.094878</td>\n",
       "      <td>-0.203264</td>\n",
       "      <td>-0.013735</td>\n",
       "      <td>-0.710345</td>\n",
       "      <td>0.172799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530583</td>\n",
       "      <td>0.187374</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260081</td>\n",
       "      <td>-0.378379</td>\n",
       "      <td>0.136987</td>\n",
       "      <td>-0.115915</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.533220</td>\n",
       "      <td>-0.063789</td>\n",
       "      <td>-0.045482</td>\n",
       "      <td>-0.551651</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.154024</td>\n",
       "      <td>0.447604</td>\n",
       "      <td>-0.103433</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181461</td>\n",
       "      <td>-0.382395</td>\n",
       "      <td>-0.453737</td>\n",
       "      <td>-0.276794</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.278046</td>\n",
       "      <td>-0.331133</td>\n",
       "      <td>0.094336</td>\n",
       "      <td>-0.628746</td>\n",
       "      <td>0.057609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facebook  GooglePlus  LinkedIn  Topic_economy  Topic_microsoft  \\\n",
       "0        -1          -1        -1              0                0   \n",
       "1        -1          -1        -1              1                0   \n",
       "2        -1          -1        -1              1                0   \n",
       "3        -1          -1        -1              1                0   \n",
       "4        -1          -1        -1              1                0   \n",
       "\n",
       "   Topic_obama  Topic_palestine        t1        t2        t3  ...       h91  \\\n",
       "0            1                0 -0.098636  0.633668 -0.693920  ... -0.543032   \n",
       "1            0                0 -0.218680  0.177207  0.278337  ... -0.463229   \n",
       "2            0                0  0.187596  0.395501 -0.322583  ... -0.193322   \n",
       "3            0                0 -0.530583  0.187374  0.015022  ... -0.260081   \n",
       "4            0                0 -0.154024  0.447604 -0.103433  ... -0.181461   \n",
       "\n",
       "        h92       h93       h94       h95       h96       h97       h98  \\\n",
       "0 -0.254333 -0.232355  0.131315 -0.091420  0.867266  0.276129 -0.160378   \n",
       "1 -0.552598 -0.715039 -0.543524 -0.573413  0.441098 -0.133821  0.311327   \n",
       "2 -0.091477 -0.482368 -0.547905 -0.584852  0.094878 -0.203264 -0.013735   \n",
       "3 -0.378379  0.136987 -0.115915  0.456800  0.533220 -0.063789 -0.045482   \n",
       "4 -0.382395 -0.453737 -0.276794  0.013191  0.278046 -0.331133  0.094336   \n",
       "\n",
       "        h99      h100  \n",
       "0  0.251298  0.509076  \n",
       "1 -0.492976  0.150883  \n",
       "2 -0.710345  0.172799  \n",
       "3 -0.551651  0.003335  \n",
       "4 -0.628746  0.057609  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[list(X.columns)] = scaler.fit_transform(X[list(X.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_columns = ['Facebook','GooglePlus',\n",
    "                'LinkedIn','Topic_economy', 'Topic_microsoft', \n",
    "                'Topic_obama','Topic_palestine']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_title_columns = main_columns+title_columns\n",
    "select_headline_columns = main_columns+headline_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title = X_train[select_title_columns]\n",
    "X_test_title = X_test[select_title_columns]\n",
    "\n",
    "Y_train_title = Y_train['SentimentTitle']\n",
    "Y_test_title = Y_test['SentimentTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_headline = X_train[select_headline_columns]\n",
    "X_test_headline = X_test[select_headline_columns]\n",
    "Y_train_headline = Y_train['SentimentHeadline']\n",
    "Y_test_headline = Y_test['SentimentHeadline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import roc_auc_score,roc_curve\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import matplotlib.pyplot as pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12545072871832552"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_title,Y_train_title)\n",
    "\n",
    "lr.score(X_train_title,Y_train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11062393874112009"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_headline,Y_train_headline)\n",
    "\n",
    "lr.score(X_train_headline,Y_train_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', n_estimators=200, verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_title = RandomForestRegressor(n_estimators=200,criterion='mse',max_features='sqrt',verbose=1)\n",
    "\n",
    "rf_title.fit(X_train_title,Y_train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', n_estimators=200, verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_headline = RandomForestRegressor(n_estimators=200,criterion='mse',max_features='sqrt',verbose=1)\n",
    "\n",
    "rf_headline.fit(X_train_headline,Y_train_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_title = rf_title.predict(X_test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3156266441286155"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_title.score(X_test_title,Y_test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21270182809263072"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_headline.score(X_test_headline,Y_test_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE error in train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_title = rf_title.predict(X_test_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "y_test_predict_headline = rf_headline.predict(X_test_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07670906559849482"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(Y_test_title-y_test_predict_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09387661345913298"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(Y_test_headline-y_test_predict_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129904056851222"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(0,1-(0.4*np.mean(abs(Y_test_title-y_test_predict_title))+0.6*np.mean(abs(Y_test_headline-y_test_predict_headline))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_columns = ['t'+str(i) for i in range(1,101)]\n",
    "headline_columns = ['h'+str(i) for i in range(1,101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('dataset/test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(data=test_df,columns=['Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['title_embedding']  = test_df.apply(lambda x: sentence_embedding(x['Title']),axis=1)\n",
    "\n",
    "test_df['headline_embedding']  = test_df.apply(lambda x: sentence_embedding(x['Headline']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dataframe_test = pd.DataFrame(test_df['title_embedding'].to_list(), columns = title_columns)\n",
    "headline_dataframe_test = pd.DataFrame(test_df['headline_embedding'].to_list(), columns = headline_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1 = pd.concat([test_df,title_dataframe_test,headline_dataframe_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1_title = test_df1[select_title_columns]\n",
    "test_df1_headline = test_df1[select_headline_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Topic_economy</th>\n",
       "      <th>Topic_microsoft</th>\n",
       "      <th>Topic_obama</th>\n",
       "      <th>Topic_palestine</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>...</th>\n",
       "      <th>t91</th>\n",
       "      <th>t92</th>\n",
       "      <th>t93</th>\n",
       "      <th>t94</th>\n",
       "      <th>t95</th>\n",
       "      <th>t96</th>\n",
       "      <th>t97</th>\n",
       "      <th>t98</th>\n",
       "      <th>t99</th>\n",
       "      <th>t100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.170861</td>\n",
       "      <td>0.585554</td>\n",
       "      <td>-0.347407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367294</td>\n",
       "      <td>-0.289588</td>\n",
       "      <td>-0.365901</td>\n",
       "      <td>-0.303176</td>\n",
       "      <td>-0.062653</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>-0.178627</td>\n",
       "      <td>-0.131225</td>\n",
       "      <td>-0.563069</td>\n",
       "      <td>-0.443287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140719</td>\n",
       "      <td>-0.166838</td>\n",
       "      <td>0.648721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425418</td>\n",
       "      <td>-0.816827</td>\n",
       "      <td>-0.902377</td>\n",
       "      <td>0.103103</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>-0.611387</td>\n",
       "      <td>0.622406</td>\n",
       "      <td>-0.315822</td>\n",
       "      <td>0.543858</td>\n",
       "      <td>0.718103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facebook  GooglePlus  LinkedIn  Topic_economy  Topic_microsoft  \\\n",
       "0         0           0         1              1                0   \n",
       "1       121           2        13              0                1   \n",
       "\n",
       "   Topic_obama  Topic_palestine        t1        t2        t3  ...       t91  \\\n",
       "0            0                0 -0.170861  0.585554 -0.347407  ... -0.367294   \n",
       "1            0                0  0.140719 -0.166838  0.648721  ... -0.425418   \n",
       "\n",
       "        t92       t93       t94       t95       t96       t97       t98  \\\n",
       "0 -0.289588 -0.365901 -0.303176 -0.062653  0.616139 -0.178627 -0.131225   \n",
       "1 -0.816827 -0.902377  0.103103 -0.000711 -0.611387  0.622406 -0.315822   \n",
       "\n",
       "        t99      t100  \n",
       "0 -0.563069 -0.443287  \n",
       "1  0.543858  0.718103  \n",
       "\n",
       "[2 rows x 107 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1_title.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-77-e203e28d3811>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df1_title[select_title_columns] = scaler.fit_transform(test_df1_title[select_title_columns])\n",
      "/Users/b0206395/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "test_df1_title[select_title_columns] = scaler.fit_transform(test_df1_title[select_title_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-fa6356f6eb38>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df1_headline[select_headline_columns] = scaler.fit_transform(test_df1_headline[select_headline_columns])\n",
      "/Users/b0206395/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "test_df1_headline[select_headline_columns] = scaler.fit_transform(test_df1_headline[select_headline_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>GooglePlus</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Topic_economy</th>\n",
       "      <th>Topic_microsoft</th>\n",
       "      <th>Topic_obama</th>\n",
       "      <th>Topic_palestine</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>...</th>\n",
       "      <th>h91</th>\n",
       "      <th>h92</th>\n",
       "      <th>h93</th>\n",
       "      <th>h94</th>\n",
       "      <th>h95</th>\n",
       "      <th>h96</th>\n",
       "      <th>h97</th>\n",
       "      <th>h98</th>\n",
       "      <th>h99</th>\n",
       "      <th>h100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459887</td>\n",
       "      <td>0.331097</td>\n",
       "      <td>0.487324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572670</td>\n",
       "      <td>0.434023</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.669624</td>\n",
       "      <td>0.573498</td>\n",
       "      <td>0.767330</td>\n",
       "      <td>0.587888</td>\n",
       "      <td>0.712400</td>\n",
       "      <td>0.519887</td>\n",
       "      <td>0.250279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00735</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564693</td>\n",
       "      <td>0.281043</td>\n",
       "      <td>0.656578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653173</td>\n",
       "      <td>0.280203</td>\n",
       "      <td>0.406907</td>\n",
       "      <td>0.490932</td>\n",
       "      <td>0.420343</td>\n",
       "      <td>0.496176</td>\n",
       "      <td>0.746641</td>\n",
       "      <td>0.609433</td>\n",
       "      <td>0.692935</td>\n",
       "      <td>0.419768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facebook  GooglePlus  LinkedIn  Topic_economy  Topic_microsoft  \\\n",
       "0   0.00006    0.000983  0.000098            1.0              0.0   \n",
       "1   0.00735    0.002950  0.000688            0.0              1.0   \n",
       "\n",
       "   Topic_obama  Topic_palestine        h1        h2        h3  ...       h91  \\\n",
       "0          0.0              0.0  0.459887  0.331097  0.487324  ...  0.572670   \n",
       "1          0.0              0.0  0.564693  0.281043  0.656578  ...  0.653173   \n",
       "\n",
       "        h92       h93       h94       h95       h96       h97       h98  \\\n",
       "0  0.434023  0.700565  0.669624  0.573498  0.767330  0.587888  0.712400   \n",
       "1  0.280203  0.406907  0.490932  0.420343  0.496176  0.746641  0.609433   \n",
       "\n",
       "        h99      h100  \n",
       "0  0.519887  0.250279  \n",
       "1  0.692935  0.419768  \n",
       "\n",
       "[2 rows x 107 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1_headline.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.07091009, -0.03334267, -0.05220521, ..., -0.02933717,\n",
       "       -0.04341188, -0.00927376])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_title.predict(test_df1_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01613106, -0.00335052, -0.01490469, ..., -0.03522935,\n",
       "       -0.03817481, -0.0331324 ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_headline.predict(test_df1_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "test_df1['SentimentTitle'] = rf_title.predict(test_df1_title)\n",
    "\n",
    "test_df1['SentimentHeadline'] = rf_headline.predict(test_df1_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = test_df1[['IDLink','SentimentTitle','SentimentHeadline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDLink</th>\n",
       "      <th>SentimentTitle</th>\n",
       "      <th>SentimentHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tFrqIR6Chj</td>\n",
       "      <td>-0.070910</td>\n",
       "      <td>-0.016131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DVAaGErjlF</td>\n",
       "      <td>-0.033343</td>\n",
       "      <td>-0.003351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OT9UIZm5M2</td>\n",
       "      <td>-0.052205</td>\n",
       "      <td>-0.014905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lflGp3q2Fj</td>\n",
       "      <td>-0.001523</td>\n",
       "      <td>-0.049912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zDYG0SoovZ</td>\n",
       "      <td>-0.015058</td>\n",
       "      <td>-0.019616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDLink  SentimentTitle  SentimentHeadline\n",
       "0  tFrqIR6Chj       -0.070910          -0.016131\n",
       "1  DVAaGErjlF       -0.033343          -0.003351\n",
       "2  OT9UIZm5M2       -0.052205          -0.014905\n",
       "3  lflGp3q2Fj       -0.001523          -0.049912\n",
       "4  zDYG0SoovZ       -0.015058          -0.019616"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('sentiment_analysis_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
